samp = config['sample']
if 'reads2' in config:
    reads = [config['reads1'], config['reads2']]
else:
    reads = config['reads1']

from os.path import join
rule all:
    input:
        reads,
        config['assembly'],
        config['krakendb'],
        # additional binning methods: metabat maxbin, concoct, mycc
        "{samp}/metabat/success.txt".format(samp=samp),
        "{samp}/maxbin/maxbin.summary".format(samp=samp),
        "{samp}/concoct/output/clustering_gt1000.csv".format(samp=samp),
        "{samp}/mycc/Cluster.summary".format(samp=samp),
        dynamic("{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa".format(samp=samp, bin="{bin}")),
        # # expand("{samp}/DAS_Tool/success.txt", samp = config['sample']),
        dynamic("{samp}/DAS_Tool/rna/trna/{bin}.fa.txt".format(samp=samp, bin="{bin}")),
        dynamic("{samp}/DAS_Tool/prokka/{bin}.fa/{samp}_{bin}.fa.gff".format(samp=samp, bin="{bin}")),
        dynamic("{samp}/DAS_Tool/coverage/raw/{bin}.tsv".format(samp=samp, bin="{bin}")),
        dynamic("{samp}/DAS_Tool/coverage/{bin}.txt".format(samp=samp, bin="{bin}")),
        dynamic("{samp}/DAS_Tool/rna/rrna/{bin}.fa.txt".format(samp=samp, bin="{bin}")),
        dynamic("{samp}/DAS_Tool/quast/{bin}.fa/report.txt".format(samp=samp, bin="{bin}")),
        # checkm for each binning method
        # expand("{samp}/metabat_checkm/checkm.tsv", samp = config['sample']),
        # expand("{samp}/maxbin_checkm/checkm.tsv", samp = config['sample']),
        # expand("{samp}/concoct_checkm/checkm.tsv", samp = config['sample']),
        # expand("{samp}/mycc_checkm/checkm.tsv", samp = config['sample']),
        "{samp}/DAS_Tool_checkm/checkm.tsv".format(samp=samp),
        # refinem for each binning method
        # expand("{samp}/metabat_refinem/ssu/ssu_erroneous.tsv", samp = config['sample']),
        # expand("{samp}/concoct_refinem/ssu/ssu_erroneous.tsv", samp = config['sample']),
        # expand("{samp}/maxbin_refinem/ssu/ssu_erroneous.tsv", samp = config['sample']),
        # expand("{samp}/mycc_refinem/ssu/ssu_erroneous.tsv", samp = config['sample']),
        # expand("{samp}/DAS_Tool_refinem/ssu/ssu_erroneous.tsv", samp = config['sample'])
        # classification and tabulation
        "{samp}/classify_kraken2/{samp}.krak".format(samp=samp),
        "{samp}/DAS_Tool/classify_kraken2/bin_species_calls.tsv".format(samp=samp),
        "{samp}/DAS_Tool/final/{samp}.tsv".format(samp=samp),
        "{samp}/DAS_Tool/final/{samp}_simple.tsv".format(samp=samp),

rule bwa_index_setup:
    input:
        config['assembly']
    output:
        ancient("{samp}/idx/{samp}.fa")
    resources:
        mem=1,
        time=1,
        cores=1
    params:
        asm = config['assembly']
    shell:
        "cp {params.asm} {samp}/idx/{samp}.fa"


rule bwa_index:
    input:
        "{samp}/idx/{samp}.fa"
    output:
        "{samp}/idx/{samp}.fa.amb",
        "{samp}/idx/{samp}.fa.ann",
        "{samp}/idx/{samp}.fa.bwt",
        "{samp}/idx/{samp}.fa.pac",
        "{samp}/idx/{samp}.fa.sa"
    log:
        "{samp}/logs/bwa_index.log"
    resources:
        mem=8,
        time=2,
        cores=1
    shell: "bwa index {input}"

rule bwa_align:
    input:
        "{samp}/idx/{samp}.fa",
        reads,
        "{samp}/idx/{samp}.fa.amb",
        "{samp}/idx/{samp}.fa.ann",
        "{samp}/idx/{samp}.fa.bwt",
        "{samp}/idx/{samp}.fa.pac",
        "{samp}/idx/{samp}.fa.sa"
    log:
        "{samp}/logs/bwa_mem.log"
    output:
        "{samp}/{samp}.bam"
    resources:
        mem=16,
        time=12,
        cores=8
    shell:
        "bwa mem -C -t {threads}" + " {input[0]} {input[1]} | samtools sort --threads {threads}" + " > {output}"

rule bam_idx:
    input:
        "{samp}/{samp}.bam"
    output:
        "{samp}/{samp}.bam.bai"
    log:
        "{samp}/logs/bamidx.log"
    resources:
        mem=2,
        time=2
    shell:
        "samtools index {input}"

rule bam_idxstats:
    input:
        bam="{samp}/{samp}.bam",
        bambai="{samp}/{samp}.bam.bai"
    output:
        "{samp}/{samp}.bam.bai.tsv"
    log:
        "{samp}/logs/bamidx.log"
    resources:
        mem=2,
        time=2
    shell:
        "samtools idxstats {input.bam} > {output}"

rule kraken2:
    input:
        contigs = "{samp}/idx/{samp}.fa",
        db = config['krakendb']
    output:
        krak = "{samp}/classify_kraken2/{samp}.krak",
        report = "{samp}/classify_kraken2/{samp}.krak.report",
        bracken1 = "{samp}/classify_kraken2/{samp}.krak.report.bracken",
        bracken2 = "{samp}/classify_kraken2/{samp}.krak_bracken.report",
    log:
        "{samp}/logs/kraken.log"
    resources:
        mem=64,
        time=1,
        cores=4
    shell:
        """
        # we just use the first two columns of the output here, so dont 
        # really need the reports or bracken
        source activate kraken2
        kraken2 --db {input.db} --output {output.krak} --report {output.report} \
         --threads {resources.cores} {input.contigs}
        bracken -d {input.db} -i {output.report} -o {output.bracken1} -r 150
        """

################################################
############### BINNING  METHODS ###############
################################################

rule metabat:
    input:
        "{samp}/idx/{samp}.fa",
        "{samp}/{samp}.bam"
    output:
        "{samp}/metabat/success.txt"
    params:
        outfolder = "{samp}/metabat"
    resources:
        mem=64,
        time=24,
        cores= 16
    shell:
        """
        if [ -d {samp}/metabat/ ]; then rm -r {samp}/metabat/; fi
        mkdir -p {samp}/metabat/bins
        runMetaBat.sh --seed 1 -t {resources.cores} --unbinned {input}
        mv {samp}.fa.metabat-bins--unbinned/* {samp}/metabat/bins/
        rmdir {samp}.fa.metabat-bins--unbinned/
        mv {samp}.fa.depth.txt {samp}/
        # mark as complete
        touch {params.outfolder}/success.txt
        """

rule maxbin:
    input:
        contigs=config['assembly'],
        reads1=reads[0],
        reads2=reads[1]
    output:
        summary="{samp}/maxbin/maxbin.summary"
    params:
        outfolder="{samp}/maxbin/"
    resources:
        cores=16,
        time=lambda wildcards, attempt: attempt * 2
    shell:
        """
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}
        cd {params.outfolder}
        MAXBIN=/home/bsiranos/software/MaxBin-2.2.5
        $MAXBIN/run_MaxBin.pl -contig {input.contigs} -out maxbin \
        -reads {input.reads1} -reads2 {input.reads2}  -thread {resources.cores}
        """
        # mv maxbin.* {output.outfolder}

rule mycc:
    input: 
        contigs=config['assembly'],
    output:
        "{samp}/mycc/Cluster.summary"
    params: 
        outfolder="{samp}/mycc/"
    resources:
        time=lambda wildcards, attempt: attempt * 12
    shell:
        """
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}
        cd {wildcards.samp}
        MyCC=/home/bsiranos/software/MyCC
        /usr/bin/python2.7 $MyCC/MyCC.py {input.contigs} -meta
        # remove these damn tempfiles that keep clogging everything up
        rm -rf {params.outfolder}/2_*
        """

rule concoct_1:
    input:
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        input_table="{samp}/concoct/concoct_inputtable.tsv",
        input_tableR="{samp}/concoct/concoct_inputtableR.tsv"
    resources:
        cores=1,
        time=1,
    params:
        outfolder="{samp}/concoct/output/",
        bins_folder="{samp}/concoct/output/bins/",
    shell:
        """
        source activate concoct
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}
        
        CONCOCT=/home/bsiranos/software/CONCOCT
        python $CONCOCT/scripts/gen_input_table.py {input.contigs} {input.mapping} > {output.input_table}
        # Parse the input table to just contain the mean coverage for each contig in each sample:
        cut -f1,3- {output.input_table} > {output.input_tableR}
        """

rule concoct_2:
    input:
        contigs=config['assembly'],
        input_table="{samp}/concoct/concoct_inputtable.tsv",
        input_tableR="{samp}/concoct/concoct_inputtableR.tsv",
    output:
        clustering="{samp}/concoct/output/clustering_gt1000.csv",
        pca="{samp}/concoct/output/PCA_transformed_data_gt1000.csv",
        pca_means="{samp}/concoct/output/pca_means_gt1000.csv",
    resources:
        cores=1,
        time=lambda wildcards, attempt: attempt * 48,
    params:
        outfolder="{samp}/concoct/output/",
        guess_clusters=40
    shell:
        """
        source activate concoct
        # Run concoct with the maximum number of cluster that we guess is appropriate for this data set:
        concoct -c {params.guess_clusters} --coverage_file {input.input_tableR} \
        --composition_file {input.contigs} -b {params.outfolder}
        """


rule concoct_3:
    input:
        contigs=config['assembly'],
        clustering="{samp}/concoct/output/clustering_gt1000.csv",
    output:
        "{samp}/concoct/output/success.txt"
    resources:
        cores=1,
        time=1
    params:
        outfolder = "{samp}/concoct/output",
        bins_folder = "{samp}/concoct/output/bins/",
    shell:
        """
        source activate concoct
        mkdir -p {params.bins_folder}
        CONCOCT=/home/bsiranos/software/CONCOCT
        # extract to bins
        python $CONCOCT/scripts/extract_fasta_bins.py {input.contigs} {input.clustering} --output_path {params.bins_folder}
        # mark as complete
        touch {params.outfolder}/success.txt
        """

rule concoct_evaluate:
    input:
        clustering="{samp}/concoct/output/clustering_gt1000.csv",
        pca="{samp}/concoct/output/PCA_transformed_data_gt1000.csv",
        pca_means="{samp}/concoct/output/pca_means_gt1000.csv"
    output:
        "{samp}/concoct/eval/cluster_plot.pdf"
    shell:
        """
        CONCOCT=/home/bsiranos/software/CONCOCT
        Rscript $CONCOCT/scripts/ClusterPlot.R -c {input.clustering} \
        -p {input.pca} -m {input.pca_means} -r {samp}/concoct/output/pca_variances_gt1000_dim \
        -l -o {output}
        """

# NO CONCOCT
# rule DAS_Tool:
#     input:
#         rules.metabat.output,
#         rules.maxbin.output,
#         rules.mycc.output,
#         # rules.concoct_3.output
#     output:
#         dynamic("{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"),
#         # dynamic("{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"),
#         # "{samp}/DAS_Tool/success.txt"
#     params:
#         outfolder="{samp}/DAS_Tool"
#     resources:
#         cores=16
#     shell:
#         """
#         if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
#         mkdir -p {params.outfolder}

#         module load usearch
#         DASTOOL=/home/bsiranos/software/DAS_Tool
#         # perpare scaffold2bin file for each 
#         $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -e fa -i {wildcards.samp}/metabat/bins/ > {wildcards.samp}/DAS_Tool/metabat_scaffold2bin.tsv
#         $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -i {wildcards.samp}/maxbin/ > {wildcards.samp}/DAS_Tool/maxbin_scaffold2bin.tsv
#         $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -i {wildcards.samp}/mycc > {wildcards.samp}/DAS_Tool/mycc_scaffold2bin.tsv

#         $DASTOOL/DAS_Tool -i {wildcards.samp}/DAS_Tool/metabat_scaffold2bin.tsv,{wildcards.samp}/DAS_Tool/maxbin_scaffold2bin.tsv,{wildcards.samp}/DAS_Tool/mycc_scaffold2bin.tsv -l metabat,maxbin,mycc -c {wildcards.samp}/idx/{samp}.fa -o {wildcards.samp}/DAS_Tool/fourmethods --threads {resources.cores} --write_bins 1 --write_unbinned 1
        
#         # samtools fiadx on all bins
#         for i in {params.outfolder}/fourmethods_DASTool_bins/*.fa; do samtools faidx $i; done

#         # mark that the tool completed successfully
#         touch {params.outfolder}/success.txt
#         """

# OLD, WITH CONCOCT
rule DAS_Tool:
    input:
        rules.metabat.output,
        rules.maxbin.output,
        rules.mycc.output,
        rules.concoct_3.output
    output:
        # dynamic("{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa")
        dynamic("{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"),
        # "{samp}/DAS_Tool/success.txt"
    params:
        outfolder="{samp}/DAS_Tool"
    resources:
        cores=16
    shell:
        """
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}

        module load usearch
        DASTOOL=/home/bsiranos/software/DAS_Tool
        # perpare scaffold2bin file for each 
        $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -e fa -i {wildcards.samp}/metabat/bins/ > {wildcards.samp}/DAS_Tool/metabat_scaffold2bin.tsv
        $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -i {wildcards.samp}/maxbin/ > {wildcards.samp}/DAS_Tool/maxbin_scaffold2bin.tsv
        $DASTOOL/src/Fasta_to_Scaffolds2Bin.sh -i {wildcards.samp}/mycc > {wildcards.samp}/DAS_Tool/mycc_scaffold2bin.tsv
        sed 's/,/\t/g' {wildcards.samp}/concoct/output/clustering_gt1000.csv > {wildcards.samp}/DAS_Tool/concoct_scaffold2bin.tsv

        $DASTOOL/DAS_Tool -i {wildcards.samp}/DAS_Tool/metabat_scaffold2bin.tsv,{wildcards.samp}/DAS_Tool/maxbin_scaffold2bin.tsv,{wildcards.samp}/DAS_Tool/mycc_scaffold2bin.tsv,{wildcards.samp}/DAS_Tool/concoct_scaffold2bin.tsv -l metabat,maxbin,mycc,concoct -c {wildcards.samp}/idx/{samp}.fa -o {wildcards.samp}/DAS_Tool/fourmethods --threads {resources.cores} --write_bins 1 --write_unbinned 1
        
        # samtools fiadx on all bins
        for i in {params.outfolder}/fourmethods_DASTool_bins/*.fa; do samtools faidx $i; done

        # mark that the tool completed successfully
        touch {params.outfolder}/success.txt
        """

################################################
################ CHECKM  BLOCKS ################
################################################
rule checkm_metabat:
    input:
        rules.metabat.output
    output:
        "{samp}/metabat_checkm/checkm.tsv"
    log:
        "{samp}/logs/checkm.log"
    resources:
        mem=128,
        time=24,
        cores=1 
    params:
        bin_folder="{samp}/metabat/bins/",
        out_folder="{samp}/metabat_checkm/",
        bin_ex=".fa"
    shell:
        """
        outdir={params.out_folder}
        if [ -d $outdir ]; then rm -r $outdir; fi
        source activate checkm
        checkm tree --threads {resources.cores} {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm tree_qa {params.out_folder}
        checkm lineage_set {params.out_folder} {params.out_folder}/lineage.ms
        checkm analyze  {params.out_folder}/lineage.ms {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm qa {params.out_folder}/lineage.ms {params.out_folder} -f {params.out_folder}/checkm.tsv --tab_table
        """

rule checkm_maxbin:
    input:
        dynamic(rules.maxbin.output)
    output:
        "{samp}/maxbin_checkm/checkm.tsv"
    resources:
        mem=128,
        time=24,
        cores=1 
    params:
        bin_folder="{samp}/maxbin/",
        out_folder="{samp}/maxbin_checkm/",
        bin_ex=".fasta"
    shell:
        """
        outdir={params.out_folder}
        if [ -d $outdir ]; then rm -r $outdir; fi
        source activate checkm
        checkm tree --threads {resources.cores} {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm tree_qa {params.out_folder}
        checkm lineage_set {params.out_folder} {params.out_folder}/lineage.ms
        checkm analyze  {params.out_folder}/lineage.ms {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm qa {params.out_folder}/lineage.ms {params.out_folder} -f {params.out_folder}/checkm.tsv --tab_table
        """

rule checkm_concoct:
    input:
        dynamic(rules.concoct_3.output)
    output:
        "{samp}/concoct_checkm/checkm.tsv"
    resources:
        mem=128,
        time=24,
        cores=1
    params:
        bin_folder="{samp}/concoct/output/bins/",
        out_folder="{samp}/concoct_checkm/",
        bin_ex=".fa" 
    shell:
        """
        outdir={params.out_folder}
        if [ -d $outdir ]; then rm -r $outdir; fi
        source activate checkm
        checkm tree --threads {resources.cores} {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm tree_qa {params.out_folder}
        checkm lineage_set {params.out_folder} {params.out_folder}/lineage.ms
        checkm analyze  {params.out_folder}/lineage.ms {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm qa {params.out_folder}/lineage.ms {params.out_folder} -f {params.out_folder}/checkm.tsv --tab_table
        """
 
rule checkm_mycc:
    input:
        dynamic(rules.mycc.output)
    output:
        "{samp}/mycc_checkm/checkm.tsv"
    resources:
        mem=128,
        time=24,
        cores=1
    params:
        bin_folder="{samp}/mycc/",
        out_folder="{samp}/mycc_checkm/",
        bin_ex=".fasta" 
    shell:
        """
        outdir={params.out_folder}
        if [ -d $outdir ]; then rm -r $outdir; fi
        source activate checkm
        checkm tree --threads {resources.cores} {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm tree_qa {params.out_folder}
        checkm lineage_set {params.out_folder} {params.out_folder}/lineage.ms
        checkm analyze  {params.out_folder}/lineage.ms {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm qa {params.out_folder}/lineage.ms {params.out_folder} -f {params.out_folder}/checkm.tsv --tab_table
        """

rule checkm_DAS_Tool:
    input:
        dynamic(rules.DAS_Tool.output)
    output:
        "{samp}/DAS_Tool_checkm/checkm.tsv"
    resources:
        mem=128,
        time=24,
        cores=1
    params:
        bin_folder="{samp}/DAS_Tool/fourmethods_DASTool_bins/",
        out_folder="{samp}/DAS_Tool_checkm/",
        bin_ex=".fa"
    shell:
        """
        outdir={params.out_folder}
        if [ -d $outdir ]; then rm -r $outdir; fi
        source activate checkm
        checkm tree --threads {resources.cores} {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm tree_qa {params.out_folder}
        checkm lineage_set {params.out_folder} {params.out_folder}/lineage.ms
        checkm analyze  {params.out_folder}/lineage.ms {params.bin_folder} {params.out_folder} -x {params.bin_ex}
        checkm qa {params.out_folder}/lineage.ms {params.out_folder} -f {params.out_folder}/checkm.tsv --tab_table
        """



################################################
########## ANALYSIS OF  DAS_TOOL BINS ##########
################################################
rule label_bins:
    input:
        dynamic(rules.DAS_Tool.output),
        krak = "{samp}/classify_kraken2/{samp}.krak",
    params:
        binfolder = "{samp}/DAS_Tool/fourmethods_DASTool_bins/"
    output:
        "{samp}/DAS_Tool/classify_kraken2/bin_species_calls.tsv"
    log:
        "{samp}/logs/assign_species.log"
    shell:
        """
        python scripts/assign_species_kraken2_direct.py {input.krak} {params.binfolder} {output}
        """

rule aragorn:
    input:
        "{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"
    output:
        "{samp}/DAS_Tool/rna/trna/{bin}.fa.txt"
    log:
        "{samp}/logs/aragorn.{bin}.log"
    resources:
        mem=8,
        time=1
    shell:
        "aragorn -t {input} -o {output}"

rule barrnap:
    input:
        "{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"
    output:
        "{samp}/DAS_Tool/rna/rrna/{bin}.fa.txt"
    log:
        "{samp}/logs/barrnap.{bin}.log"
    resources:
        mem=8,
        time=1
    shell:
        "barrnap {input} > {output}"

rule quast:
    input:
        "{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"
    output:
        "{samp}/DAS_Tool/quast/{bin}.fa/report.txt"
    log:
        "{samp}/logs/quast.{bin}.log"
    params:
        outfolder="{samp}/DAS_Tool/quast/{bin}.fa/"
    resources:
        mem=8,
        time=1
    shell:
        """
        module load quast
        qst=$(which quast.py)
        /usr/bin/python2.7 $qst -o {params.outfolder} {input} --contig-thresholds 0,10000,50000,100000,250000,500000,1000000,2000000,3000000 --fast --min-contig 250
        """

rule prokka:
    input:
        "{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa"
    output:
        "{samp}/DAS_Tool/prokka/{bin}.fa/{samp}_{bin}.fa.gff"
    log:
        "{samp}/logs/prokka.{bin}.log"
    resources:
        mem=48,
        time=6,
        cores= 16
    shell:
        "prokka {input} --outdir {samp}/DAS_Tool/prokka/{wildcards.bin}.fa " +
        "--prefix {samp}_{wildcards.bin}.fa  --force --cpus {threads}"

rule bin_idxstats:
    input:
        "{samp}/DAS_Tool/fourmethods_DASTool_bins/{bin}.fa",
        "{samp}/{samp}.bam.bai.tsv"
    output:
        "{samp}/DAS_Tool/coverage/raw/{bin}.tsv"
    log:
        "{samp}/logs/coverage.{bin}.log"
    resources:
        mem=2,
        time=4
    shell:
        """
        grep '>' {input[0]} | tr -d '>' | cut -f 1 -d ' ' | xargs -I foo -n 1 grep -P 'foo\t' {input[1]} > {output}
        """
rule bin_coverage:
    input:
        "{samp}/DAS_Tool/coverage/raw/{bin}.tsv"
    output:
        "{samp}/DAS_Tool/coverage/{bin}.txt"
    log:
        "{samp}/logs/coverage.{bin}.log"
    resources:
        mem=2,
        time=4
    params:
        read_length = config['read_length']
    script:
        "scripts/bin_coverage.py"

################################################
################ POSTPROCESSING ################
################################################

rule postprocess_raw:
    input:
        # rules.prokka.output,
        # rules.quast.output,
        # rules.checkm_DAS_Tool.output,
        # rules.aragorn.output,
        # rules.barrnap.output,
        # rules.bin_coverage.output,
        # rules.label_bins.output,
        dynamic(rules.prokka.output),
        dynamic(rules.quast.output),
        rules.checkm_DAS_Tool.output,
        dynamic(rules.aragorn.output),
        dynamic(rules.barrnap.output),
        dynamic(rules.bin_coverage.output),
        rules.label_bins.output
    output:
        "{samp}/DAS_Tool/final/prokka.tmp",
        "{samp}/DAS_Tool/final/quast.tmp",
        "{samp}/DAS_Tool/final/checkm.tmp",
        "{samp}/DAS_Tool/final/trna.tmp",
        "{samp}/DAS_Tool/final/rrna.tmp",
        "{samp}/DAS_Tool/final/classify.tmp",
        "{samp}/DAS_Tool/final/coverage.tmp"
    log:
        "{samp}/logs/postprocess.log"
    resources:
        mem=2,
        time=1
    shell: #TODO: tuck this away into a shell script.
        """
        # coverage
        (echo -e 'Sample\tBin\tCoverage'; cat {samp}/DAS_Tool/coverage/*.txt) > {samp}/DAS_Tool/final/coverage.tmp
        # prokka
        (echo -e 'Sample\tBin\tGenes'; find {samp}/DAS_Tool/prokka/ -name '*.gff' | xargs grep -c CDS | cut -f5 -d '/' | sed 's/.fa.gff:/\t/g' | sed 's/{samp}_/{samp}\t/g' | sort -k2,2g) > {samp}/DAS_Tool/final/prokka.tmp
        # quast
        find {samp}/DAS_Tool/quast/ -name 'transposed_report.tsv' | xargs head -qn1 | sort -u | sed 's/^Assembly/Sample\tBin/g' > {samp}/DAS_Tool/final/quast.tmp
        find {samp}/DAS_Tool/quast/ -name 'transposed_report.tsv' | xargs tail -qn+2 | sort -u | sed 's/^/{samp}\t/g' >> {samp}/DAS_Tool/final/quast.tmp
        # checkm
        head -qn1 {samp}/DAS_Tool_checkm/checkm.tsv | sed 's/^Bin Id/Sample\tBin/g' > {samp}/DAS_Tool/final/checkm.tmp
        tail -qn+2 {samp}/DAS_Tool_checkm/checkm.tsv | sed 's/^/{samp}\t/g' >> {samp}/DAS_Tool/final/checkm.tmp
        # trna
        (echo -e 'Sample\tBin\ttRNA'; grep Total {samp}/DAS_Tool/rna/trna/* | sed 's/\/rna\/trna\//\t/g' | sed 's/.fa.txt:Total tRNA genes = /\t/g') > {samp}/DAS_Tool/final/trna.tmp
        #rrna
        (echo -e 'Sample\tBin\trna.16S\trna.23S\trna.5S'; paste <(grep -c 16S {samp}/DAS_Tool/rna/rrna/* | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g') \
        <(grep -c 23S {samp}/DAS_Tool/rna/rrna/* | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g' | cut -f4) \
        <(grep -c 5S {samp}/DAS_Tool/rna/rrna/* | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g' | cut -f4)) > {samp}/DAS_Tool/final/rrna.tmp
        # classify

        cat {samp}/DAS_Tool/classify_kraken2/bin_species_calls.tsv | sed 's/\.fa//g' > {samp}/DAS_Tool/final/classify.tmp
        """
        
rule postprocess_final:
    input:
        "{samp}/DAS_Tool/final/prokka.tmp",
        "{samp}/DAS_Tool/final/quast.tmp",
        "{samp}/DAS_Tool/final/checkm.tmp",
        "{samp}/DAS_Tool/final/trna.tmp",
        "{samp}/DAS_Tool/final/rrna.tmp",
        "{samp}/DAS_Tool/final/classify.tmp",
        "{samp}/DAS_Tool/final/coverage.tmp"
    output:
        "{samp}/DAS_Tool/final/{samp}.tsv"
    log:
        "{samp}/logs/postprocess.log"
    shell:
        """
        # Rscript join_final_tables_direct.R prokka quast checkm trna rrna classify coverage out")

        Rscript scripts/join_final_tables_direct.R {input} {output}
        """

rule postprocess_simplify:
    input:
        "{samp}/DAS_Tool/final/{samp}.tsv"
    output:
        "{samp}/DAS_Tool/final/{samp}_simple.tsv"
    shell:
        """
        # awk 'BEGIN {{FS="\t"}} {{OFS="\t"}} {{print($1,$2,$47,$50,$48,$49,$51,$40,$41,$42,$4,$23,$25,$26)}}' {input} > {output}
        awk 'BEGIN {{FS="\t"}} {{OFS="\t"}} {{print($2,$1,$48,$49,$50,$51,$52,$53,$47,$54,$40,$41,$42,$4,$23,$25,$26)}}' {input} > {output}
        """


################################################
################ REFINEM BLOCKS ################
########## You probably dont need this #########
################################################
rule refinem_concoct:
    input:
        rules.concoct_3.output,
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        scaffold_stats_folder="{samp}/concoct_refinem/scaffold_stats/",
        scaffold_stats="{samp}/concoct_refinem/scaffold_stats/scaffold_stats.tsv",
        outliers_folder="{samp}/concoct_refinem/outliers/",
        outliers="{samp}/concoct_refinem/outliers/outliers.tsv",
        bins_filtered_genomic_folder="{samp}/concoct_refinem/bins_filtered_genomic/",
        called_genes_folder="{samp}/concoct_refinem/called_genes/",
        called_genes_filtered_folder="{samp}/concoct_refinem/called_genes_filtered/",
        taxon_profile_folder="{samp}/concoct_refinem/taxon_profile",
        taxon_filter="{samp}/concoct_refinem/taxon_profile/taxon_filter.tsv",
        bins_filtered_taxonomic_folder="{samp}/concoct_refinem/bins_filtered_taxonomic/",
        ssu_folder="{samp}/concoct_refinem/ssu/",
        ssu_erroneous="{samp}/concoct_refinem/ssu/ssu_erroneous.tsv",
        bins_filtered_ssu_folder="{samp}/concoct_refinem/bins_filtered_ssu/",
    params:
        bins_folder="{samp}/concoct/output/bins/",
        bin_ex=".fa"
    resources:
        cores=32
    shell:
        """
        REFDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_protein_db.2017-11-09.faa
        SSUDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_ssu_db.2018-01-18.fna
        REFTAXONOMY=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_taxonomy.2017-12-15.tsv
        
        # scaffold stats
        refinem scaffold_stats -c {resources.cores} {input.contigs} {input.bins_folder} \
            {output.scaffold_stats_folder} {input.mapping} -x {params.bin_ex}
        # filter outliers with divergent scaffold stats
        refinem outliers {output.scaffold_stats} {output.outliers_folder} --no_plots
        refinem filter_bins {input.bins_folder} {output.outliers} \
            {output.bins_filtered_genomic_folder} -x {params.bin_ex}
        
        # call genes on unfiltered bins - can also use filtered here
        refinem call_genes -c {resources.cores} {input.bins_folder} {output.called_genes_folder} -x {params.bin_ex}
        # on filtered by genomic outliers 
        refinem call_genes -c {resources.cores} {output.bins_filtered_genomic_folder} \
            {output.called_genes_filtered_folder} -x {params.bin_ex}
        
        # Generate taxonomic profile of genes across scaffolds within a genome
        # initially using the unfiltered contigs
        refinem taxon_profile -c {resources.cores} {output.called_genes_folder} \
        {output.scaffold_stats} $REFDB $REFTAXONOMY {output.taxon_profile_folder}
        # Identify scaffolds with divergent taxonomic classification
        refinem taxon_filter -c {resources.cores} {output.taxon_profile_folder} {output.taxon_filter}
        # filter by taxoniomic classification        
        refinem filter_bins {input.bins_folder} {output.taxon_filter} {output.bins_filtered_taxonomic_folder} -x {params.bin_ex}
        
        # Identify scaffolds with erroneous 16S rRNA genes
        refinem ssu_erroneous {input.bins_folder} {output.taxon_profile_folder} \
            $SSUDB $REFTAXONOMY {output.ssu_folder} -x {params.bin_ex}
        # filter by erroneous 16S rRNA genes
        refinem filter_bins {input.bins_folder} {output.ssu_erroneous} \
            {output.bins_filtered_ssu_folder} -x {params.bin_ex}
        """

rule refinem_metabat:
    input:
        rules.metabat.output,
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        scaffold_stats_folder="{samp}/metabat_refinem/scaffold_stats/",
        scaffold_stats="{samp}/metabat_refinem/scaffold_stats/scaffold_stats.tsv",
        outliers_folder="{samp}/metabat_refinem/outliers/",
        outliers="{samp}/metabat_refinem/outliers/outliers.tsv",
        bins_filtered_genomic_folder="{samp}/metabat_refinem/bins_filtered_genomic/",
        called_genes_folder="{samp}/metabat_refinem/called_genes/",
        called_genes_filtered_folder="{samp}/metabat_refinem/called_genes_filtered/",
        taxon_profile_folder="{samp}/metabat_refinem/taxon_profile",
        taxon_filter="{samp}/metabat_refinem/taxon_profile/taxon_filter.tsv",
        bins_filtered_taxonomic_folder="{samp}/metabat_refinem/bins_filtered_taxonomic/",
        ssu_folder="{samp}/metabat_refinem/ssu/",
        ssu_erroneous="{samp}/metabat_refinem/ssu/ssu_erroneous.tsv",
        bins_filtered_ssu_folder="{samp}/metabat_refinem/bins_filtered_ssu/",
    params:
        bins_folder="{samp}/bins/",
        bin_ex=".fa"
    resources:
        cores=32
    shell:
        """
        REFDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_protein_db.2017-11-09.faa
        SSUDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_ssu_db.2018-01-18.fna
        REFTAXONOMY=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_taxonomy.2017-12-15.tsv
        
        # scaffold stats
        refinem scaffold_stats -c {resources.cores} {input.contigs} {params.bins_folder} \
            {output.scaffold_stats_folder} {input.mapping} -x {params.bin_ex}
        # filter outliers with divergent scaffold stats
        refinem outliers {output.scaffold_stats} {output.outliers_folder} --no_plots
        refinem filter_bins {params.bins_folder} {output.outliers} \
            {output.bins_filtered_genomic_folder} -x {params.bin_ex}
        
        # call genes on unfiltered bins - can also use filtered here
        refinem call_genes -c {resources.cores} {params.bins_folder} {output.called_genes_folder} -x {params.bin_ex}
        # on filtered by genomic outliers 
        refinem call_genes -c {resources.cores} {output.bins_filtered_genomic_folder} \
            {output.called_genes_filtered_folder} -x {params.bin_ex}
        
        # Generate taxonomic profile of genes across scaffolds within a genome
        # initially using the unfiltered contigs
        refinem taxon_profile -c {resources.cores} {output.called_genes_folder} \
        {output.scaffold_stats} $REFDB $REFTAXONOMY {output.taxon_profile_folder}
        # Identify scaffolds with divergent taxonomic classification
        refinem taxon_filter -c {resources.cores} {output.taxon_profile_folder} {output.taxon_filter}
        # filter by taxoniomic classification        
        refinem filter_bins {params.bins_folder} {output.taxon_filter} {output.bins_filtered_taxonomic_folder} -x {params.bin_ex}
        
        # Identify scaffolds with erroneous 16S rRNA genes
        refinem ssu_erroneous {params.bins_folder} {output.taxon_profile_folder} \
            $SSUDB $REFTAXONOMY {output.ssu_folder} -x {params.bin_ex}
        # filter by erroneous 16S rRNA genes
        refinem filter_bins {params.bins_folder} {output.ssu_erroneous} \
            {output.bins_filtered_ssu_folder} -x {params.bin_ex}
        """

rule refinem_maxbin:
    input:
        rules.maxbin.output,
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        scaffold_stats_folder="{samp}/maxbin_refinem/scaffold_stats/",
        scaffold_stats="{samp}/maxbin_refinem/scaffold_stats/scaffold_stats.tsv",
        outliers_folder="{samp}/maxbin_refinem/outliers/",
        outliers="{samp}/maxbin_refinem/outliers/outliers.tsv",
        bins_filtered_genomic_folder="{samp}/maxbin_refinem/bins_filtered_genomic/",
        called_genes_folder="{samp}/maxbin_refinem/called_genes/",
        called_genes_filtered_folder="{samp}/maxbin_refinem/called_genes_filtered/",
        taxon_profile_folder="{samp}/maxbin_refinem/taxon_profile",
        taxon_filter="{samp}/maxbin_refinem/taxon_profile/taxon_filter.tsv",
        bins_filtered_taxonomic_folder="{samp}/maxbin_refinem/bins_filtered_taxonomic/",
        ssu_folder="{samp}/maxbin_refinem/ssu/",
        ssu_erroneous="{samp}/maxbin_refinem/ssu/ssu_erroneous.tsv",
        bins_filtered_ssu_folder="{samp}/maxbin_refinem/bins_filtered_ssu/",
    params:
        bins_folder="{samp}/maxbin/",
        bin_ex=".fasta"
    resources:
        cores=32
    shell:
        """
        REFDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_protein_db.2017-11-09.faa
        SSUDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_ssu_db.2018-01-18.fna
        REFTAXONOMY=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_taxonomy.2017-12-15.tsv
        
        # scaffold stats
        refinem scaffold_stats -c {resources.cores} {input.contigs} {params.bins_folder} \
            {output.scaffold_stats_folder} {input.mapping} -x {params.bin_ex}
        # filter outliers with divergent scaffold stats
        refinem outliers {output.scaffold_stats} {output.outliers_folder} --no_plots
        refinem filter_bins {params.bins_folder} {output.outliers} \
            {output.bins_filtered_genomic_folder} -x {params.bin_ex}
        
        # call genes on unfiltered bins - can also use filtered here
        refinem call_genes -c {resources.cores} {params.bins_folder} {output.called_genes_folder} -x {params.bin_ex}
        # on filtered by genomic outliers 
        refinem call_genes -c {resources.cores} {output.bins_filtered_genomic_folder} \
            {output.called_genes_filtered_folder} -x {params.bin_ex}
        
        # Generate taxonomic profile of genes across scaffolds within a genome
        # initially using the unfiltered contigs
        refinem taxon_profile -c {resources.cores} {output.called_genes_folder} \
        {output.scaffold_stats} $REFDB $REFTAXONOMY {output.taxon_profile_folder}
        # Identify scaffolds with divergent taxonomic classification
        refinem taxon_filter -c {resources.cores} {output.taxon_profile_folder} {output.taxon_filter}
        # filter by taxoniomic classification        
        refinem filter_bins {params.bins_folder} {output.taxon_filter} {output.bins_filtered_taxonomic_folder} -x {params.bin_ex}
        
        # Identify scaffolds with erroneous 16S rRNA genes
        refinem ssu_erroneous {params.bins_folder} {output.taxon_profile_folder} \
            $SSUDB $REFTAXONOMY {output.ssu_folder} -x {params.bin_ex}
        # filter by erroneous 16S rRNA genes
        refinem filter_bins {params.bins_folder} {output.ssu_erroneous} \
            {output.bins_filtered_ssu_folder} -x {params.bin_ex}
        """

rule refinem_mycc:
    input:
        rules.mycc.output,
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        scaffold_stats_folder="{samp}/mycc_refinem/scaffold_stats/",
        scaffold_stats="{samp}/mycc_refinem/scaffold_stats/scaffold_stats.tsv",
        outliers_folder="{samp}/mycc_refinem/outliers/",
        outliers="{samp}/mycc_refinem/outliers/outliers.tsv",
        bins_filtered_genomic_folder="{samp}/mycc_refinem/bins_filtered_genomic/",
        called_genes_folder="{samp}/mycc_refinem/called_genes/",
        called_genes_filtered_folder="{samp}/mycc_refinem/called_genes_filtered/",
        taxon_profile_folder="{samp}/mycc_refinem/taxon_profile",
        taxon_filter="{samp}/mycc_refinem/taxon_profile/taxon_filter.tsv",
        bins_filtered_taxonomic_folder="{samp}/mycc_refinem/bins_filtered_taxonomic/",
        ssu_folder="{samp}/mycc_refinem/ssu/",
        ssu_erroneous="{samp}/mycc_refinem/ssu/ssu_erroneous.tsv",
        bins_filtered_ssu_folder="{samp}/mycc_refinem/bins_filtered_ssu/",
    params:
        bins_folder="{samp}/mycc/",
        bin_ex=".fasta"
    resources:
        cores=32
    shell:
        """
        REFDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_protein_db.2017-11-09.faa
        SSUDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_ssu_db.2018-01-18.fna
        REFTAXONOMY=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_taxonomy.2017-12-15.tsv
        
        # scaffold stats
        refinem scaffold_stats -c {resources.cores} {input.contigs} {params.bins_folder} \
            {output.scaffold_stats_folder} {input.mapping} -x {params.bin_ex}
        # filter outliers with divergent scaffold stats
        refinem outliers {output.scaffold_stats} {output.outliers_folder} --no_plots
        refinem filter_bins {params.bins_folder} {output.outliers} \
            {output.bins_filtered_genomic_folder} -x {params.bin_ex}
        
        # call genes on unfiltered bins - can also use filtered here
        refinem call_genes -c {resources.cores} {params.bins_folder} {output.called_genes_folder} -x {params.bin_ex}
        # on filtered by genomic outliers 
        refinem call_genes -c {resources.cores} {output.bins_filtered_genomic_folder} \
            {output.called_genes_filtered_folder} -x {params.bin_ex}
        
        # Generate taxonomic profile of genes across scaffolds within a genome
        # initially using the unfiltered contigs
        refinem taxon_profile -c {resources.cores} {output.called_genes_folder} \
        {output.scaffold_stats} $REFDB $REFTAXONOMY {output.taxon_profile_folder}
        # Identify scaffolds with divergent taxonomic classification
        refinem taxon_filter -c {resources.cores} {output.taxon_profile_folder} {output.taxon_filter}
        # filter by taxoniomic classification        
        refinem filter_bins {params.bins_folder} {output.taxon_filter} {output.bins_filtered_taxonomic_folder} -x {params.bin_ex}
        
        # Identify scaffolds with erroneous 16S rRNA genes
        refinem ssu_erroneous {params.bins_folder} {output.taxon_profile_folder} \
            $SSUDB $REFTAXONOMY {output.ssu_folder} -x {params.bin_ex}
        # filter by erroneous 16S rRNA genes
        refinem filter_bins {params.bins_folder} {output.ssu_erroneous} \
            {output.bins_filtered_ssu_folder} -x {params.bin_ex}
        """

rule refinem_DAS_Tool:
    input:
        rules.DAS_Tool.output, 
        contigs=config['assembly'],
        mapping="{samp}/{samp}.bam"
    output:
        scaffold_stats_folder="{samp}/DAS_Tool_refinem/scaffold_stats/",
        scaffold_stats="{samp}/DAS_Tool_refinem/scaffold_stats/scaffold_stats.tsv",
        outliers_folder="{samp}/DAS_Tool_refinem/outliers/",
        outliers="{samp}/DAS_Tool_refinem/outliers/outliers.tsv",
        bins_filtered_genomic_folder="{samp}/DAS_Tool_refinem/bins_filtered_genomic/",
        called_genes_folder="{samp}/DAS_Tool_refinem/called_genes/",
        called_genes_filtered_folder="{samp}/DAS_Tool_refinem/called_genes_filtered/",
        taxon_profile_folder="{samp}/DAS_Tool_refinem/taxon_profile",
        taxon_filter="{samp}/DAS_Tool_refinem/taxon_profile/taxon_filter.tsv",
        bins_filtered_taxonomic_folder="{samp}/DAS_Tool_refinem/bins_filtered_taxonomic/",
        ssu_folder="{samp}/DAS_Tool_refinem/ssu/",
        ssu_erroneous="{samp}/DAS_Tool_refinem/ssu/ssu_erroneous.tsv",
        bins_filtered_ssu_folder="{samp}/DAS_Tool_refinem/bins_filtered_ssu/",
    params:
        bins_folder="{samp}/DAS_Tool/fourmethods_DASTool_bins/",
        bin_ex=".fa"
    resources:
        cores=32
    shell:
        """
        REFDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_protein_db.2017-11-09.faa
        SSUDB=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_ssu_db.2018-01-18.fna
        REFTAXONOMY=/labs/asbhatt/bsiranos/refinem_db/gtdb_r80_taxonomy.2017-12-15.tsv
        
        # scaffold stats
        refinem scaffold_stats -c {resources.cores} {input.contigs} {params.bins_folder} \
            {output.scaffold_stats_folder} {input.mapping} -x {params.bin_ex}
        # filter outliers with divergent scaffold stats
        refinem outliers {output.scaffold_stats} {output.outliers_folder} --no_plots
        refinem filter_bins {params.bins_folder} {output.outliers} \
            {output.bins_filtered_genomic_folder} -x {params.bin_ex}
        
        # call genes on unfiltered bins - can also use filtered here
        refinem call_genes -c {resources.cores} {params.bins_folder} {output.called_genes_folder} -x {params.bin_ex}
        # on filtered by genomic outliers 
        refinem call_genes -c {resources.cores} {output.bins_filtered_genomic_folder} \
            {output.called_genes_filtered_folder} -x {params.bin_ex}
        
        # Generate taxonomic profile of genes across scaffolds within a genome
        # initially using the unfiltered contigs
        refinem taxon_profile -c {resources.cores} {output.called_genes_folder} \
        {output.scaffold_stats} $REFDB $REFTAXONOMY {output.taxon_profile_folder}
        # Identify scaffolds with divergent taxonomic classification
        refinem taxon_filter -c {resources.cores} {output.taxon_profile_folder} {output.taxon_filter}
        # filter by taxoniomic classification        
        refinem filter_bins {params.bins_folder} {output.taxon_filter} {output.bins_filtered_taxonomic_folder} -x {params.bin_ex}
        
        # Identify scaffolds with erroneous 16S rRNA genes
        refinem ssu_erroneous {params.bins_folder} {output.taxon_profile_folder} \
            $SSUDB $REFTAXONOMY {output.ssu_folder} -x {params.bin_ex}
        # filter by erroneous 16S rRNA genes
        refinem filter_bins {params.bins_folder} {output.ssu_erroneous} \
            {output.bins_filtered_ssu_folder} -x {params.bin_ex}
        """